{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beautiful Soup is used for parsing the html code and finding elements within it to properly extract key pieces of data\n",
    "from bs4 import BeautifulSoup as soup\n",
    "#Im using splinter to navigate the browser with an automated testing system, logging in, click buttons, and such...\n",
    "from splinter import Browser\n",
    "# Importing Pandas to read the CSV files\n",
    "import pandas as pd\n",
    "#==== May not need whatever is below =====\n",
    "# # Importing date-time\n",
    "# import datetime as dt\n",
    "# importing time so Python can sleep, making net32 think we are not launching a denial of service attack\n",
    "import time \n",
    "\n",
    "# The python event scheduler\n",
    "import schedule \n",
    "\n",
    "executable_path = {'executable_path':'chromedriver.exe'}\n",
    "browser = Browser('chrome',**executable_path, headless = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.supremenewyork.com/\"\n",
    "\n",
    "browser.visit(url)\n",
    "\n",
    "browser.click_link_by_href(\"/shop\")\n",
    "\n",
    "# Rendering the HTML Shop page \n",
    "html = browser.html\n",
    "page_soup = soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLOURS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving all the jacket(s), t-shirt(s), and shirt(s)  that are currently present on Supreme \n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# Rendering the HTML Shop page \n",
    "html = browser.html\n",
    "page_soup = soup(html, 'html.parser')\n",
    "\n",
    "jackets = page_soup.find_all(\"li\",class_ = \"jackets\")\n",
    "tshirts = page_soup.find_all(\"li\", class_ = \"t-shirts\")\n",
    "shirts = page_soup.find_all(\"li\",class_ = \"shirts\")\n",
    "topSweaters = page_soup.find_all(\"li\",class_ = \"tops/sweaters\")\n",
    "pants = page_soup.find_all(\"li\",class_ = \"pants\")\n",
    "\n",
    "## Creating individual lists for grainularity purposes\n",
    "jacketList = []\n",
    "tshirtList = []\n",
    "shirtList= []\n",
    "topSweatersList = []\n",
    "pantsList = []\n",
    "\n",
    "## Creating an aggregate clothingList to store all the clothng Hrefs into one list for faster robot activity\n",
    "clothingList= []\n",
    "\n",
    "## For loop collecting all the jacket HREFs\n",
    "for i in range(0,len(jackets)):\n",
    "    jacketList.append(jackets[i].a['href'])\n",
    "    clothingList.append(jackets[i].a['href'])\n",
    "#     print(jackets[i].a['href'])\n",
    "\n",
    "## For loop collecting all the tshirt HREFs\n",
    "for i in range(0,len(tshirts)):\n",
    "    tshirtList.append(tshirts[i].a['href'])\n",
    "    clothingList.append(tshirts[i].a['href'])\n",
    "#     print(tshirts[i].a['href'])\n",
    "\n",
    "## For loop collecting all the shirts HREFs\n",
    "for i in range(0,len(shirts)):\n",
    "    shirtList.append(shirts[i].a['href'])\n",
    "    clothingList.append(shirts[i].a['href'])\n",
    "#     print(shirts[i].a['href'])\n",
    "\n",
    "## For loop collecting all the tops/sweaters HREFs\n",
    "for i in range(0,len(topSweaters)):\n",
    "    topSweatersList.append(topSweaters[i].a['href'])\n",
    "    clothingList.append(topSweaters[i].a['href'])\n",
    "#     print(topSweaters[i].a['href'])\n",
    "    \n",
    "## For loop collecting all the pants HREFs\n",
    "for i in range(0,len(pants)):\n",
    "    pantsList.append(pants[i].a['href'])\n",
    "    clothingList.append(pants[i].a['href'])\n",
    "#     print(pants[i].a['href'])\n",
    "\n",
    "\n",
    "## Sleep\n",
    "time.sleep(1.5)\n",
    "\n",
    "\n",
    "### Setting the code to navigate to colours \n",
    "# Rendering the HTML for a given clothing page \n",
    "html = browser.html\n",
    "page_soup = soup(html, 'html.parser')\n",
    "\n",
    "\n",
    "## creating a colours list to store all the kinds of colours for all given clothing products\n",
    "colourList = []\n",
    "\n",
    "## Sleep\n",
    "time.sleep(1.5)\n",
    "\n",
    "### Creating a for loopto naviaget through the HREF's collected for all jackets, shirts, tshirts, \n",
    "for item in clothingList:\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Visiting the webpage for a given item\n",
    "    browser.click_link_by_href(item)\n",
    "    \n",
    "    # letting the system sleep for a second\n",
    "    time.sleep(1.5)\n",
    "    \n",
    "    # Rendering the HTML for a given clothing page \n",
    "    html = browser.html\n",
    "    page_soup = soup(html, 'html.parser')\n",
    "    \n",
    "    # letting the system sleep for a second\n",
    "    time.sleep(5)\n",
    "    \n",
    "    ## Creating a if statement to check all UL's of the html page to find the \"styles\" tag on a given clothing page\n",
    "    ## and whhen the condition is true, then picking up all the colours available for sale for that given clothing article \n",
    "    for i in range(0,len(page_soup.find_all(\"ul\"))):\n",
    "        try:\n",
    "            if page_soup.find_all(\"ul\")[i]['class'][0][:6] == 'styles':\n",
    "                # If true, then navigate to the options of colours and retain the \n",
    "                amountOfColours = len(page_soup.find_all(\"ul\")[i].find_all('li'))\n",
    "                for c in range(0,amountOfColours):\n",
    "                    if page_soup.find_all(\"ul\")[i].find_all('li')[c].button['data-style-name'] not in colourList:\n",
    "                        colourList.append(page_soup.find_all(\"ul\")[i].find_all('li')[c].button['data-style-name'])\n",
    "                        print(page_soup.find_all(\"ul\")[i].find_all('li')[c].button['data-style-name'])\n",
    "\n",
    "            else:\n",
    "                print('false')\n",
    "        except KeyError:\n",
    "            pass\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    browser.back()\n",
    "\n",
    "colourList.to_csv(\"coloursListSupreme.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIZES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium\n",
      "Large\n",
      "XLarge\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "Small\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "### Saving all the jacket(s), t-shirt(s), and shirt(s)  that are currently present on Supreme \n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# Rendering the HTML Shop page \n",
    "html = browser.html\n",
    "page_soup = soup(html, 'html.parser')\n",
    "\n",
    "jackets = page_soup.find_all(\"li\",class_ = \"jackets\")\n",
    "tshirts = page_soup.find_all(\"li\", class_ = \"t-shirts\")\n",
    "shirts = page_soup.find_all(\"li\",class_ = \"shirts\")\n",
    "topSweaters = page_soup.find_all(\"li\",class_ = \"tops/sweaters\")\n",
    "pants = page_soup.find_all(\"li\",class_ = \"pants\")\n",
    "\n",
    "## Creating individual lists for grainularity purposes\n",
    "jacketList = []\n",
    "tshirtList = []\n",
    "shirtList= []\n",
    "topSweatersList = []\n",
    "pantsList = []\n",
    "\n",
    "## Creating an aggregate clothingList to store all the clothng Hrefs into one list for faster robot activity\n",
    "clothingList= []\n",
    "\n",
    "## For loop collecting all the jacket HREFs\n",
    "for i in range(0,len(jackets)):\n",
    "    jacketList.append(jackets[i].a['href'])\n",
    "    clothingList.append(jackets[i].a['href'])\n",
    "#     print(jackets[i].a['href'])\n",
    "\n",
    "## For loop collecting all the tshirt HREFs\n",
    "for i in range(0,len(tshirts)):\n",
    "    tshirtList.append(tshirts[i].a['href'])\n",
    "    clothingList.append(tshirts[i].a['href'])\n",
    "#     print(tshirts[i].a['href'])\n",
    "\n",
    "## For loop collecting all the shirts HREFs\n",
    "for i in range(0,len(shirts)):\n",
    "    shirtList.append(shirts[i].a['href'])\n",
    "    clothingList.append(shirts[i].a['href'])\n",
    "#     print(shirts[i].a['href'])\n",
    "\n",
    "## For loop collecting all the tops/sweaters HREFs\n",
    "for i in range(0,len(topSweaters)):\n",
    "    topSweatersList.append(topSweaters[i].a['href'])\n",
    "    clothingList.append(topSweaters[i].a['href'])\n",
    "#     print(topSweaters[i].a['href'])\n",
    "    \n",
    "## For loop collecting all the pants HREFs\n",
    "for i in range(0,len(pants)):\n",
    "    pantsList.append(pants[i].a['href'])\n",
    "    clothingList.append(pants[i].a['href'])\n",
    "#     print(pants[i].a['href'])\n",
    "\n",
    "\n",
    "## Sleep\n",
    "time.sleep(1.5)\n",
    "\n",
    "\n",
    "### Setting the code to navigate to sizes \n",
    "# Rendering the HTML for a given clothing page \n",
    "html = browser.html\n",
    "page_soup = soup(html, 'html.parser')\n",
    "\n",
    "\n",
    "## creating a colours list to store all the kinds of colours for all given clothing products\n",
    "sizeList = []\n",
    "\n",
    "## Sleep\n",
    "time.sleep(1.5)\n",
    "\n",
    "### Creating a for loopto naviaget through the HREF's collected for all jackets, shirts, tshirts, \n",
    "for item in clothingList:\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Visiting the webpage for a given item\n",
    "    browser.click_link_by_href(item)\n",
    "    \n",
    "    # letting the system sleep for a second\n",
    "    time.sleep(1.5)\n",
    "    \n",
    "    # Rendering the HTML for a given clothing page \n",
    "    html = browser.html\n",
    "    page_soup = soup(html, 'html.parser')\n",
    "    \n",
    "    # letting the system sleep for a second\n",
    "    time.sleep(5)\n",
    "\n",
    "    try:\n",
    "        if page_soup.findAll(\"fieldset\")[0].find_all(\"option\")[0].text:\n",
    "\n",
    "            ## Creating a if statement to check all UL's of the html page to find the \"styles\" tag on a given clothing page\n",
    "            ## and whhen the condition is true, then picking up all the colours available for sale for that given clothing article \n",
    "            for i in range(0,len(page_soup.findAll(\"fieldset\")[0].find_all(\"option\"))):\n",
    "\n",
    "                if page_soup.findAll(\"fieldset\")[0].find_all(\"option\")[i].text not in sizeList:\n",
    "                    sizeList.append(page_soup.findAll(\"fieldset\")[0].find_all(\"option\")[i].text)\n",
    "                    print(page_soup.findAll(\"fieldset\")[0].find_all(\"option\")[i].text)\n",
    "\n",
    "                else:\n",
    "                    print('false')\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "    except IndexError:\n",
    "        pass\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    browser.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeListDF = pd.DataFrame(sizeList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XLarge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0  Medium\n",
       "1   Large\n",
       "2  XLarge\n",
       "3   Small\n",
       "4      30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizeListDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeListDF.to_csv(\"supremeSizeList.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
